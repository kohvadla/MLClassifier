{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deselected_features ['dsid', 'event_weight', 'lep_charge1', 'lep_charge2', 'n_bjets']\n",
      "\n",
      "selected_features = ['dPhi_jj_ll', 'dPhi_jj_met', 'dPhi_ll_met', 'dR_jj', 'dR_ll', 'jet_eta1', 'jet_eta2', 'jet_eta3', 'jet_m1', 'jet_m2', 'jet_m3', 'jet_phi1', 'jet_phi2', 'jet_phi3', 'jet_pt1', 'jet_pt2', 'jet_pt3', 'lep_eta1', 'lep_eta2', 'lep_phi1', 'lep_phi2', 'lep_pt1', 'lep_pt2', 'met', 'met_phi', 'mjj', 'mll', 'n_jets', 'pt_jj', 'pt_ll']\n",
      "\n",
      "n_selected_features = 30\n",
      "\n",
      "Read in background file: ../../../ewk/hdf5_files/2L_bkg_flat_ext.h5\n",
      "Read in signal file: ../../../ewk/hdf5_files/2L_sig_flat_ext.h5\n",
      "\n",
      "class_weight_vect [1. 1.]\n",
      "class_weight_dict {0: 1.0, 1: 1.0}\n",
      "\n",
      "scale_pos_weight 1.0\n",
      "\n",
      "before imp: np.any(X_bkg_sel_arr == -999) True\n",
      "before imp: np.any(X_bkg_shuffled == -999) False\n",
      "after imp: np.any(X == -999) False\n",
      "\n",
      "# training examples:\n",
      "Background  : 570\n",
      "Signal      : 571\n",
      "\n",
      "# test examples:\n",
      "Background  : 282\n",
      "Signal      : 281\n",
      "\n",
      "INFO  Applying event weights to the examples during training\n",
      "\n",
      "model.get_params() {'base_estimator__min_samples_split': 2, 'base_estimator__max_depth': 1, 'algorithm': 'SAMME.R', 'learning_rate': 1.0, 'base_estimator': DecisionTreeClassifier(class_weight={0: 1.0, 1: 1.0}, criterion='gini',\n",
      "            max_depth=1, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), 'base_estimator__criterion': 'gini', 'base_estimator__max_features': None, 'base_estimator__random_state': None, 'n_estimators': 100, 'base_estimator__min_weight_fraction_leaf': 0.0, 'random_state': None, 'base_estimator__class_weight': {0: 1.0, 1: 1.0}, 'base_estimator__splitter': 'best', 'base_estimator__max_leaf_nodes': None, 'base_estimator__min_samples_leaf': 1, 'base_estimator__presort': False, 'base_estimator__min_impurity_split': 1e-07}\n",
      "\n",
      "Building and training BDT\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 37.089853271842\n",
      "sum_weights_test_bkg 6.082574092783034\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 111.26955981552601 , B = 5613.916042436984\n",
      "sum_weights_test_sig/acceptance_sig = 111.26955981552601\n",
      "cut = 0.0 , ams_br10 =  1.4788843564178284\n",
      "new optimal cut: 0.0 , with ams_br10: 1.4788843564178284 , S = 111.26955981552601 , B = 5613.916042436984\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 19.426792725920677\n",
      "sum_weights_test_bkg 0.3714554337784648\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 58.28037817776203 , B = 342.83505419416775\n",
      "sum_weights_test_sig/acceptance_sig = 58.28037817776203\n",
      "cut = 0.05 , ams_br10 =  3.02265331957065\n",
      "new optimal cut: 0.05 , with ams_br10: 3.02265331957065 , S = 58.28037817776203 , B = 342.83505419416775\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 2.5984593108296394\n",
      "sum_weights_test_bkg 0.01837373897433281\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 7.795377932488918 , B = 16.958055325613266\n",
      "sum_weights_test_sig/acceptance_sig = 7.795377932488918\n",
      "cut = 0.1 , ams_br10 =  1.4365671232129091\n",
      "new optimal cut: 0.1 , with ams_br10: 1.4365671232129091 , S = 7.795377932488918 , B = 16.958055325613266\n",
      "\n",
      "--------------------------------------\n",
      "Assigning font /F1 = u'/eos/user/k/kvadla/.local/lib/python2.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf'\n",
      "\n",
      "----- TRAINING -----\n",
      "Confusion matrix, without normalization\n",
      "[[429 141]\n",
      " [  1 570]]\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[0.75 0.25]\n",
      " [0.   1.  ]]\n",
      "\n",
      "----- TESTING -----\n",
      "Confusion matrix, without normalization\n",
      "[[194  88]\n",
      " [ 19 262]]\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[0.69 0.31]\n",
      " [0.07 0.93]]\n",
      "Embedding font /eos/user/k/kvadla/.local/lib/python2.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf.\n",
      "Writing TrueType font.\n",
      "\n",
      "Training sample....\n",
      "  Signal identified as signal (%)        :  99.8248686515\n",
      "  Signal identified as background (%)    :  0.175131348511\n",
      "  Background identified as signal (%)    :  24.7368421053\n",
      "  Background identified as background (%):  75.2631578947\n",
      "\n",
      "Testing sample....\n",
      "  Signal identified as signal (%)        :  93.2384341637\n",
      "  Signal identified as background (%)    :  6.7615658363\n",
      "  Background identified as signal (%)    :  31.2056737589\n",
      "  Background identified as background (%):  68.7943262411\n",
      "\n",
      "Area under ROC =  0.882221549178466\n",
      "\n",
      "sum_weights_test_sig 0.12929023802280426\n",
      "sum_weights_test_bkg 0.0\n",
      "\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "\n",
      "clf_cut 0.0\n",
      "\n",
      "S 7.795377932488918\n",
      "B 16.958055325613266\n",
      "N 24.753433258102184\n",
      "np.sqrt(N) 4.9752822289898475\n",
      "\n",
      "*****************************\n",
      "Optimized AMS score (br=0) =  1.7702520597213964\n",
      "Optimized AMS score (br=10) =  1.4365671232129091\n",
      "Optimized cut value =  0.1\n",
      "S/sqrt(N) = 1.5668212522833396\n",
      "*****************************\n",
      "\n",
      "Plots saved to plots/adaboost_2L_flat_ext_ew.pdf\n",
      "\n",
      "Process time: 4.17028307915\n"
     ]
    }
   ],
   "source": [
    "%run classifiers.py --adaboost --cut_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deselected_features ['dsid', 'event_weight', 'lep_charge1', 'lep_charge2', 'n_bjets']\n",
      "\n",
      "selected_features = ['dPhi_jj_ll', 'dPhi_jj_met', 'dPhi_ll_met', 'dR_jj', 'dR_ll', 'jet_eta1', 'jet_eta2', 'jet_eta3', 'jet_m1', 'jet_m2', 'jet_m3', 'jet_phi1', 'jet_phi2', 'jet_phi3', 'jet_pt1', 'jet_pt2', 'jet_pt3', 'lep_eta1', 'lep_eta2', 'lep_phi1', 'lep_phi2', 'lep_pt1', 'lep_pt2', 'met', 'met_phi', 'mjj', 'mll', 'n_jets', 'pt_jj', 'pt_ll']\n",
      "\n",
      "n_selected_features = 30\n",
      "\n",
      "Read in background file: ../../../ewk/hdf5_files/2L_bkg_flat_ext.h5\n",
      "Read in signal file: ../../../ewk/hdf5_files/2L_sig_flat_ext.h5\n",
      "\n",
      "class_weight_vect [1. 1.]\n",
      "class_weight_dict {0: 1.0, 1: 1.0}\n",
      "\n",
      "scale_pos_weight 1.0\n",
      "\n",
      "before imp: np.any(X_bkg_sel_arr == -999) True\n",
      "before imp: np.any(X_bkg_shuffled == -999) False\n",
      "after imp: np.any(X == -999) False\n",
      "\n",
      "# training examples:\n",
      "Background  : 570\n",
      "Signal      : 571\n",
      "\n",
      "# test examples:\n",
      "Background  : 282\n",
      "Signal      : 281\n",
      "\n",
      "INFO  Applying event weights to the examples during training\n",
      "\n",
      "model.get_params() {'reg_alpha': 0, 'n_jobs': 1, 'colsample_bytree': 1, 'silent': True, 'colsample_bylevel': 1, 'scale_pos_weight': 1.0, 'learning_rate': 0.1, 'missing': None, 'max_delta_step': 0, 'nthread': None, 'base_score': 0.5, 'n_estimators': 100, 'subsample': 1, 'reg_lambda': 1, 'random_state': 0, 'min_child_weight': 1, 'objective': 'binary:logistic', 'seed': None, 'max_depth': 3, 'gamma': 0, 'booster': 'gbtree'}\n",
      "\n",
      "Building and training BDT\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 38.40919750183821\n",
      "sum_weights_test_bkg 17.341452387627214\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 115.22759250551462 , B = 16005.305693450951\n",
      "sum_weights_test_sig/acceptance_sig = 115.22759250551462\n",
      "cut = 0.5 , ams_br10 =  0.9094301248955591\n",
      "new optimal cut: 0.5 , with ams_br10: 0.9094301248955591 , S = 115.22759250551462 , B = 16005.305693450951\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 37.600641660392284\n",
      "sum_weights_test_bkg 16.696049846243113\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 112.80192498117685 , B = 15409.630963371663\n",
      "sum_weights_test_sig/acceptance_sig = 112.80192498117685\n",
      "cut = 0.6 , ams_br10 =  0.9073008039897871\n",
      "new optimal cut: 0.6 , with ams_br10: 0.9073008039897871 , S = 112.80192498117685 , B = 15409.630963371663\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 36.23536778241396\n",
      "sum_weights_test_bkg 5.370334160979837\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 108.70610334724188 , B = 4956.5536958018065\n",
      "sum_weights_test_sig/acceptance_sig = 108.70610334724188\n",
      "cut = 0.7 , ams_br10 =  1.536927962913811\n",
      "new optimal cut: 0.7 , with ams_br10: 1.536927962913811 , S = 108.70610334724188 , B = 4956.5536958018065\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 33.10962748527527\n",
      "sum_weights_test_bkg 3.7782701165415347\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 99.3288824558258 , B = 3487.1570648156126\n",
      "sum_weights_test_sig/acceptance_sig = 99.3288824558258\n",
      "cut = 0.8 , ams_br10 =  1.6717883980061397\n",
      "new optimal cut: 0.8 , with ams_br10: 1.6717883980061397 , S = 99.3288824558258 , B = 3487.1570648156126\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 31.334945648908615\n",
      "sum_weights_test_bkg 3.4997040247544646\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 94.00483694672585 , B = 3230.0542942274324\n",
      "sum_weights_test_sig/acceptance_sig = 94.00483694672585\n",
      "cut = 0.85 , ams_br10 =  1.643591982371225\n",
      "new optimal cut: 0.85 , with ams_br10: 1.643591982371225 , S = 94.00483694672585 , B = 3230.0542942274324\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 26.781246930360794\n",
      "sum_weights_test_bkg 2.0649957628920674\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 80.34374079108238 , B = 1905.889293583602\n",
      "sum_weights_test_sig/acceptance_sig = 80.34374079108238\n",
      "cut = 0.9 , ams_br10 =  1.8229426060256035\n",
      "new optimal cut: 0.9 , with ams_br10: 1.8229426060256035 , S = 80.34374079108238 , B = 1905.889293583602\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 15.170455798506737\n",
      "sum_weights_test_bkg 0.42958179814741015\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 45.51136739552021 , B = 396.48282312254526\n",
      "sum_weights_test_sig/acceptance_sig = 45.51136739552021\n",
      "cut = 0.95 , ams_br10 =  2.2170772779897683\n",
      "new optimal cut: 0.95 , with ams_br10: 2.2170772779897683 , S = 45.51136739552021 , B = 396.48282312254526\n",
      "Assigning font /F1 = u'/eos/user/k/kvadla/.local/lib/python2.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_93/x86_64-slc6-gcc62-opt/lib/python2.7/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_93/x86_64-slc6-gcc62-opt/lib/python2.7/site-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- TRAINING -----\n",
      "Confusion matrix, without normalization\n",
      "[[359 211]\n",
      " [  6 565]]\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[0.63 0.37]\n",
      " [0.01 0.99]]\n",
      "\n",
      "----- TESTING -----\n",
      "Confusion matrix, without normalization\n",
      "[[176 106]\n",
      " [ 10 271]]\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[0.62 0.38]\n",
      " [0.04 0.96]]\n",
      "Embedding font /eos/user/k/kvadla/.local/lib/python2.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf.\n",
      "Writing TrueType font.\n",
      "\n",
      "Training sample....\n",
      "  Signal identified as signal (%)        :  98.9492119089\n",
      "  Signal identified as background (%)    :  1.05078809107\n",
      "  Background identified as signal (%)    :  37.0175438596\n",
      "  Background identified as background (%):  62.9824561404\n",
      "\n",
      "Testing sample....\n",
      "  Signal identified as signal (%)        :  96.4412811388\n",
      "  Signal identified as background (%)    :  3.55871886121\n",
      "  Background identified as signal (%)    :  37.5886524823\n",
      "  Background identified as background (%):  62.4113475177\n",
      "\n",
      "Area under ROC =  0.8888720627949824\n",
      "\n",
      "sum_weights_test_sig 15.170455798506737\n",
      "sum_weights_test_bkg 0.42958179814741015\n",
      "\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "\n",
      "clf_cut 0.0\n",
      "\n",
      "S 45.51136739552021\n",
      "B 396.48282312254526\n",
      "N 441.99419051806547\n",
      "np.sqrt(N) 21.023657876736518\n",
      "\n",
      "*****************************\n",
      "Optimized AMS score (br=0) =  2.2438796470634603\n",
      "Optimized AMS score (br=10) =  2.2170772779897683\n",
      "Optimized cut value =  0.95\n",
      "S/sqrt(N) = 2.1647692167727044\n",
      "*****************************\n",
      "\n",
      "Plots saved to plots/xgboost_2L_flat_ext_ew.pdf\n",
      "\n",
      "Process time: 3.61454200745\n"
     ]
    }
   ],
   "source": [
    "%run classifiers.py --xgboost --cut_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deselected_features ['dsid', 'event_weight', 'lep_charge1', 'lep_charge2', 'n_bjets']\n",
      "\n",
      "selected_features = ['dPhi_jj_ll', 'dPhi_jj_met', 'dPhi_ll_met', 'dR_jj', 'dR_ll', 'jet_eta1', 'jet_eta2', 'jet_eta3', 'jet_m1', 'jet_m2', 'jet_m3', 'jet_phi1', 'jet_phi2', 'jet_phi3', 'jet_pt1', 'jet_pt2', 'jet_pt3', 'lep_eta1', 'lep_eta2', 'lep_phi1', 'lep_phi2', 'lep_pt1', 'lep_pt2', 'met', 'met_phi', 'mjj', 'mll', 'n_jets', 'pt_jj', 'pt_ll']\n",
      "\n",
      "n_selected_features = 30\n",
      "\n",
      "Read in background file: ../../../ewk/hdf5_files/2L_bkg_flat_ext.h5\n",
      "Read in signal file: ../../../ewk/hdf5_files/2L_sig_flat_ext.h5\n",
      "\n",
      "class_weight_vect [1. 1.]\n",
      "class_weight_dict {0: 1.0, 1: 1.0}\n",
      "\n",
      "scale_pos_weight 1.0\n",
      "\n",
      "before imp: np.any(X_bkg_sel_arr == -999) True\n",
      "before imp: np.any(X_bkg_shuffled == -999) False\n",
      "after imp: np.any(X == -999) False\n",
      "\n",
      "# training examples:\n",
      "Background  : 570\n",
      "Signal      : 571\n",
      "\n",
      "# test examples:\n",
      "Background  : 282\n",
      "Signal      : 281\n",
      "\n",
      "INFO  Applying event weights to the examples during training\n",
      "\n",
      "Building and training neural network\n",
      "\n",
      "Epoch 1/100\n",
      "1141/1141 [==============================] - 0s 367us/step - loss: 0.0772 - acc: 0.5188\n",
      "Epoch 2/100\n",
      "1141/1141 [==============================] - 0s 26us/step - loss: 0.0737 - acc: 0.4978\n",
      "Epoch 3/100\n",
      "1141/1141 [==============================] - 0s 34us/step - loss: 0.0722 - acc: 0.4996\n",
      "Epoch 4/100\n",
      "1141/1141 [==============================] - 0s 23us/step - loss: 0.0710 - acc: 0.4996\n",
      "Epoch 5/100\n",
      "1141/1141 [==============================] - 0s 21us/step - loss: 0.0703 - acc: 0.5004\n",
      "Epoch 6/100\n",
      "1141/1141 [==============================] - 0s 47us/step - loss: 0.0694 - acc: 0.5031\n",
      "Epoch 7/100\n",
      "1141/1141 [==============================] - 0s 26us/step - loss: 0.0687 - acc: 0.5022\n",
      "Epoch 8/100\n",
      "1141/1141 [==============================] - 0s 48us/step - loss: 0.0683 - acc: 0.4996\n",
      "Epoch 9/100\n",
      "1141/1141 [==============================] - ETA: 0s - loss: 0.0402 - acc: 0.560 - 0s 25us/step - loss: 0.0674 - acc: 0.5004\n",
      "Epoch 10/100\n",
      "1141/1141 [==============================] - 0s 64us/step - loss: 0.0669 - acc: 0.5031\n",
      "Epoch 11/100\n",
      "1141/1141 [==============================] - 0s 29us/step - loss: 0.0663 - acc: 0.5031\n",
      "Epoch 12/100\n",
      "1141/1141 [==============================] - 0s 50us/step - loss: 0.0655 - acc: 0.5031\n",
      "Epoch 13/100\n",
      "1141/1141 [==============================] - 0s 30us/step - loss: 0.0649 - acc: 0.5066\n",
      "Epoch 14/100\n",
      "1141/1141 [==============================] - 0s 54us/step - loss: 0.0643 - acc: 0.5083\n",
      "Epoch 15/100\n",
      "1141/1141 [==============================] - 0s 30us/step - loss: 0.0641 - acc: 0.5057\n",
      "Epoch 16/100\n",
      "1141/1141 [==============================] - 0s 62us/step - loss: 0.0635 - acc: 0.5066\n",
      "Epoch 17/100\n",
      "1141/1141 [==============================] - 0s 28us/step - loss: 0.0628 - acc: 0.5057\n",
      "Epoch 18/100\n",
      "1141/1141 [==============================] - 0s 56us/step - loss: 0.0623 - acc: 0.5092\n",
      "Epoch 19/100\n",
      "1141/1141 [==============================] - 0s 28us/step - loss: 0.0620 - acc: 0.5048\n",
      "Epoch 20/100\n",
      "1141/1141 [==============================] - 0s 60us/step - loss: 0.0613 - acc: 0.5101\n",
      "Epoch 21/100\n",
      "1141/1141 [==============================] - 0s 27us/step - loss: 0.0610 - acc: 0.5118\n",
      "Epoch 22/100\n",
      "1141/1141 [==============================] - 0s 32us/step - loss: 0.0603 - acc: 0.5066\n",
      "Epoch 23/100\n",
      "1141/1141 [==============================] - 0s 57us/step - loss: 0.0607 - acc: 0.5110\n",
      "Epoch 24/100\n",
      "1141/1141 [==============================] - 0s 33us/step - loss: 0.0601 - acc: 0.5136\n",
      "Epoch 25/100\n",
      "1141/1141 [==============================] - 0s 55us/step - loss: 0.0596 - acc: 0.5092\n",
      "Epoch 26/100\n",
      "1141/1141 [==============================] - 0s 26us/step - loss: 0.0593 - acc: 0.5083\n",
      "Epoch 27/100\n",
      "1141/1141 [==============================] - 0s 54us/step - loss: 0.0586 - acc: 0.5039\n",
      "Epoch 28/100\n",
      "1141/1141 [==============================] - 0s 27us/step - loss: 0.0584 - acc: 0.5066\n",
      "Epoch 29/100\n",
      "1141/1141 [==============================] - 0s 58us/step - loss: 0.0583 - acc: 0.5039\n",
      "Epoch 30/100\n",
      "1141/1141 [==============================] - 0s 26us/step - loss: 0.0582 - acc: 0.5057\n",
      "Epoch 31/100\n",
      "1141/1141 [==============================] - 0s 61us/step - loss: 0.0577 - acc: 0.5048\n",
      "Epoch 32/100\n",
      "1141/1141 [==============================] - 0s 31us/step - loss: 0.0573 - acc: 0.5022\n",
      "Epoch 33/100\n",
      "1141/1141 [==============================] - 0s 54us/step - loss: 0.0571 - acc: 0.5074\n",
      "Epoch 34/100\n",
      "1141/1141 [==============================] - 0s 27us/step - loss: 0.0567 - acc: 0.4978\n",
      "Epoch 35/100\n",
      "1141/1141 [==============================] - 0s 53us/step - loss: 0.0569 - acc: 0.5048\n",
      "Epoch 36/100\n",
      "1141/1141 [==============================] - 0s 31us/step - loss: 0.0562 - acc: 0.5013\n",
      "Epoch 37/100\n",
      "1141/1141 [==============================] - 0s 64us/step - loss: 0.0559 - acc: 0.4934: 0s - loss: 0.0632 - acc: 0.495\n",
      "Epoch 38/100\n",
      "1141/1141 [==============================] - 0s 39us/step - loss: 0.0560 - acc: 0.5039\n",
      "Epoch 39/100\n",
      "1141/1141 [==============================] - 0s 51us/step - loss: 0.0558 - acc: 0.5013\n",
      "Epoch 40/100\n",
      "1141/1141 [==============================] - 0s 27us/step - loss: 0.0554 - acc: 0.5031\n",
      "Epoch 41/100\n",
      "1141/1141 [==============================] - 0s 59us/step - loss: 0.0554 - acc: 0.4978\n",
      "Epoch 42/100\n",
      "1141/1141 [==============================] - ETA: 0s - loss: 0.0453 - acc: 0.510 - 0s 31us/step - loss: 0.0551 - acc: 0.4987\n",
      "Epoch 43/100\n",
      "1141/1141 [==============================] - 0s 33us/step - loss: 0.0548 - acc: 0.4934\n",
      "Epoch 44/100\n",
      "1141/1141 [==============================] - 0s 59us/step - loss: 0.0548 - acc: 0.4987\n",
      "Epoch 45/100\n",
      "1141/1141 [==============================] - 0s 33us/step - loss: 0.0544 - acc: 0.4996\n",
      "Epoch 46/100\n",
      "1141/1141 [==============================] - 0s 58us/step - loss: 0.0545 - acc: 0.5022\n",
      "Epoch 47/100\n",
      "1141/1141 [==============================] - 0s 29us/step - loss: 0.0542 - acc: 0.4996\n",
      "Epoch 48/100\n",
      "1141/1141 [==============================] - 0s 59us/step - loss: 0.0540 - acc: 0.4961: 0s - loss: 0.0535 - acc: 0.483\n",
      "Epoch 49/100\n",
      "1141/1141 [==============================] - 0s 30us/step - loss: 0.0538 - acc: 0.5022\n",
      "Epoch 50/100\n",
      "1141/1141 [==============================] - 0s 62us/step - loss: 0.0535 - acc: 0.5004\n",
      "Epoch 51/100\n",
      "1141/1141 [==============================] - 0s 29us/step - loss: 0.0536 - acc: 0.5039\n",
      "Epoch 52/100\n",
      "1141/1141 [==============================] - 0s 29us/step - loss: 0.0534 - acc: 0.5039\n",
      "Epoch 53/100\n",
      "1141/1141 [==============================] - 0s 30us/step - loss: 0.0533 - acc: 0.5004\n",
      "Epoch 54/100\n",
      "1141/1141 [==============================] - 0s 49us/step - loss: 0.0530 - acc: 0.5004\n",
      "Epoch 55/100\n",
      "1141/1141 [==============================] - 0s 28us/step - loss: 0.0528 - acc: 0.5048\n",
      "Epoch 56/100\n",
      "1141/1141 [==============================] - 0s 60us/step - loss: 0.0527 - acc: 0.5057\n",
      "Epoch 57/100\n",
      "1141/1141 [==============================] - 0s 57us/step - loss: 0.0525 - acc: 0.5039\n",
      "Epoch 58/100\n",
      "1141/1141 [==============================] - 0s 32us/step - loss: 0.0523 - acc: 0.5004\n",
      "Epoch 59/100\n",
      "1141/1141 [==============================] - 0s 55us/step - loss: 0.0523 - acc: 0.5039: 0s - loss: 0.0518 - acc: 0.500\n",
      "Epoch 60/100\n",
      "1141/1141 [==============================] - 0s 32us/step - loss: 0.0519 - acc: 0.5048\n",
      "Epoch 61/100\n",
      "1141/1141 [==============================] - 0s 60us/step - loss: 0.0518 - acc: 0.5031\n",
      "Epoch 62/100\n",
      "1141/1141 [==============================] - 0s 30us/step - loss: 0.0516 - acc: 0.5039\n",
      "Epoch 63/100\n",
      "1141/1141 [==============================] - 0s 58us/step - loss: 0.0515 - acc: 0.5083\n",
      "Epoch 64/100\n",
      "1141/1141 [==============================] - 0s 28us/step - loss: 0.0514 - acc: 0.5039\n",
      "Epoch 65/100\n",
      "1141/1141 [==============================] - 0s 66us/step - loss: 0.0510 - acc: 0.5048\n",
      "Epoch 66/100\n",
      "1141/1141 [==============================] - 0s 55us/step - loss: 0.0512 - acc: 0.5101\n",
      "Epoch 67/100\n",
      "1141/1141 [==============================] - 0s 33us/step - loss: 0.0510 - acc: 0.5048\n",
      "Epoch 68/100\n",
      "1141/1141 [==============================] - 0s 58us/step - loss: 0.0507 - acc: 0.5057\n",
      "Epoch 69/100\n",
      "1141/1141 [==============================] - 0s 32us/step - loss: 0.0505 - acc: 0.5066\n",
      "Epoch 70/100\n",
      "1141/1141 [==============================] - 0s 56us/step - loss: 0.0503 - acc: 0.5110\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141/1141 [==============================] - 0s 30us/step - loss: 0.0502 - acc: 0.5092\n",
      "Epoch 72/100\n",
      "1141/1141 [==============================] - 0s 53us/step - loss: 0.0500 - acc: 0.5118\n",
      "Epoch 73/100\n",
      "1141/1141 [==============================] - 0s 29us/step - loss: 0.0499 - acc: 0.5101\n",
      "Epoch 74/100\n",
      "1141/1141 [==============================] - 0s 57us/step - loss: 0.0496 - acc: 0.5083\n",
      "Epoch 75/100\n",
      "1141/1141 [==============================] - 0s 29us/step - loss: 0.0495 - acc: 0.5101\n",
      "Epoch 76/100\n",
      "1141/1141 [==============================] - 0s 56us/step - loss: 0.0494 - acc: 0.5074\n",
      "Epoch 77/100\n",
      "1141/1141 [==============================] - 0s 31us/step - loss: 0.0492 - acc: 0.5110\n",
      "Epoch 78/100\n",
      "1141/1141 [==============================] - 0s 55us/step - loss: 0.0490 - acc: 0.5145\n",
      "Epoch 79/100\n",
      "1141/1141 [==============================] - 0s 29us/step - loss: 0.0488 - acc: 0.5110\n",
      "Epoch 80/100\n",
      "1141/1141 [==============================] - 0s 57us/step - loss: 0.0488 - acc: 0.5145\n",
      "Epoch 81/100\n",
      "1141/1141 [==============================] - 0s 31us/step - loss: 0.0486 - acc: 0.5171\n",
      "Epoch 82/100\n",
      "1141/1141 [==============================] - 0s 57us/step - loss: 0.0483 - acc: 0.5180\n",
      "Epoch 83/100\n",
      "1141/1141 [==============================] - 0s 31us/step - loss: 0.0483 - acc: 0.5188\n",
      "Epoch 84/100\n",
      "1141/1141 [==============================] - 0s 31us/step - loss: 0.0481 - acc: 0.5153\n",
      "Epoch 85/100\n",
      "1141/1141 [==============================] - 0s 29us/step - loss: 0.0478 - acc: 0.5162\n",
      "Epoch 86/100\n",
      "1141/1141 [==============================] - ETA: 0s - loss: 0.0653 - acc: 0.550 - 0s 32us/step - loss: 0.0478 - acc: 0.5215\n",
      "Epoch 87/100\n",
      "1141/1141 [==============================] - 0s 56us/step - loss: 0.0474 - acc: 0.5223\n",
      "Epoch 88/100\n",
      "1141/1141 [==============================] - 0s 29us/step - loss: 0.0474 - acc: 0.5206\n",
      "Epoch 89/100\n",
      "1141/1141 [==============================] - 0s 56us/step - loss: 0.0470 - acc: 0.5215\n",
      "Epoch 90/100\n",
      "1141/1141 [==============================] - 0s 29us/step - loss: 0.0471 - acc: 0.5197\n",
      "Epoch 91/100\n",
      "1141/1141 [==============================] - 0s 57us/step - loss: 0.0468 - acc: 0.5180\n",
      "Epoch 92/100\n",
      "1141/1141 [==============================] - 0s 29us/step - loss: 0.0467 - acc: 0.5232\n",
      "Epoch 93/100\n",
      "1141/1141 [==============================] - 0s 52us/step - loss: 0.0465 - acc: 0.5285\n",
      "Epoch 94/100\n",
      "1141/1141 [==============================] - 0s 34us/step - loss: 0.0463 - acc: 0.5259\n",
      "Epoch 95/100\n",
      "1141/1141 [==============================] - 0s 52us/step - loss: 0.0462 - acc: 0.5267\n",
      "Epoch 96/100\n",
      "1141/1141 [==============================] - 0s 27us/step - loss: 0.0460 - acc: 0.5302\n",
      "Epoch 97/100\n",
      "1141/1141 [==============================] - 0s 58us/step - loss: 0.0457 - acc: 0.5285\n",
      "Epoch 98/100\n",
      "1141/1141 [==============================] - 0s 27us/step - loss: 0.0457 - acc: 0.5320\n",
      "Epoch 99/100\n",
      "1141/1141 [==============================] - 0s 56us/step - loss: 0.0454 - acc: 0.5285\n",
      "Epoch 100/100\n",
      "1141/1141 [==============================] - 0s 31us/step - loss: 0.0451 - acc: 0.5276\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 30.787162370979786\n",
      "sum_weights_test_bkg 8.550122982822359\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 92.36148711293936 , B = 7891.342028209264\n",
      "sum_weights_test_sig/acceptance_sig = 92.36148711293936\n",
      "cut = 0.7 , ams_br10 =  1.0370451398965834\n",
      "new optimal cut: 0.7 , with ams_br10: 1.0370451398965834 , S = 92.36148711293936 , B = 7891.342028209264\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 23.92911373823881\n",
      "sum_weights_test_bkg 3.7339973845519125\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 71.78734121471643 , B = 3446.2955156478106\n",
      "sum_weights_test_sig/acceptance_sig = 71.78734121471643\n",
      "cut = 0.8 , ams_br10 =  1.2168844727399049\n",
      "new optimal cut: 0.8 , with ams_br10: 1.2168844727399049 , S = 71.78734121471643 , B = 3446.2955156478106\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 17.60618645697832\n",
      "sum_weights_test_bkg 2.8894755449146032\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 52.81855937093496 , B = 2666.843489020866\n",
      "sum_weights_test_sig/acceptance_sig = 52.81855937093496\n",
      "cut = 0.85 , ams_br10 =  1.01755088669444\n",
      "new optimal cut: 0.85 , with ams_br10: 1.01755088669444 , S = 52.81855937093496 , B = 2666.843489020866\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 10.68668320775032\n",
      "sum_weights_test_bkg 1.7898235186003149\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 32.06004962325096 , B = 1651.9188769312582\n",
      "sum_weights_test_sig/acceptance_sig = 32.06004962325096\n",
      "cut = 0.9 , ams_br10 =  0.7839201779347968\n",
      "new optimal cut: 0.9 , with ams_br10: 0.7839201779347968 , S = 32.06004962325096 , B = 1651.9188769312582\n",
      "\n",
      "--------------------------------------\n",
      "sum_weights_test_sig 3.122410126030445\n",
      "sum_weights_test_bkg 0.7055281340144575\n",
      "X_bkg_dset.shape[0] 262118\n",
      "X_bkg_sel_shuffled.shape[0] 852\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "S = 9.367230378091335 , B = 651.1676881394421\n",
      "sum_weights_test_sig/acceptance_sig = 9.367230378091335\n",
      "cut = 0.95 , ams_br10 =  0.3634416589936064\n",
      "new optimal cut: 0.95 , with ams_br10: 0.3634416589936064 , S = 9.367230378091335 , B = 651.1676881394421\n",
      "Assigning font /F1 = u'/eos/user/k/kvadla/.local/lib/python2.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf'\n",
      "layer.name dense_11\n",
      "layer.name dense_12\n",
      "\n",
      "----- TRAINING -----\n",
      "Confusion matrix, without normalization\n",
      "[[ 81 489]\n",
      " [ 48 523]]\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[0.14 0.86]\n",
      " [0.08 0.92]]\n",
      "\n",
      "----- TESTING -----\n",
      "Confusion matrix, without normalization\n",
      "[[ 54 228]\n",
      " [ 17 264]]\n",
      "\n",
      "Normalized confusion matrix\n",
      "[[0.19 0.81]\n",
      " [0.06 0.94]]\n",
      "Embedding font /eos/user/k/kvadla/.local/lib/python2.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf.\n",
      "Writing TrueType font.\n",
      "\n",
      "Training sample....\n",
      "  Signal identified as signal (%)        :  91.5936952715\n",
      "  Signal identified as background (%)    :  8.40630472855\n",
      "  Background identified as signal (%)    :  85.7894736842\n",
      "  Background identified as background (%):  14.2105263158\n",
      "\n",
      "Testing sample....\n",
      "  Signal identified as signal (%)        :  93.9501779359\n",
      "  Signal identified as background (%)    :  6.04982206406\n",
      "  Background identified as signal (%)    :  80.8510638298\n",
      "  Background identified as background (%):  19.1489361702\n",
      "\n",
      "Area under ROC =  0.5909366245173013\n",
      "\n",
      "sum_weights_test_sig 3.122410126030445\n",
      "sum_weights_test_bkg 0.7055281340144575\n",
      "\n",
      "acceptance_sig 0.333333333333\n",
      "acceptance_bkg 0.00108348148544\n",
      "\n",
      "clf_cut 0.0\n",
      "\n",
      "S 9.367230378091335\n",
      "B 651.1676881394421\n",
      "N 660.5349185175335\n",
      "np.sqrt(N) 25.700873886261796\n",
      "\n",
      "*****************************\n",
      "Optimized AMS score (br=0) =  0.366208563266702\n",
      "Optimized AMS score (br=10) =  0.3634416589936064\n",
      "Optimized cut value =  0.95\n",
      "S/sqrt(N) = 0.3644712790524417\n",
      "*****************************\n",
      "\n",
      "Plots saved to plots/nn_2L_flat_ext_ew.pdf\n",
      "\n",
      "Process time: 10.277410984\n"
     ]
    }
   ],
   "source": [
    "%run classifiers.py --nn --cut_scan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
